{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv('train_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texto</th>\n",
       "      <th>Etiqueta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>¿Puedo reservar un turno para la próxima semana?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quisiera agendar una cita médica para el marte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>¿Están disponibles los turnos para el especial...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Necesito una cita con el odontólogo lo antes p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>¿Podría obtener un horario para una consulta d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>seguro de salud de la institución</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>seguro de seguro de salud aceptado por la inst...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>seguro de seguro médico que acepta la institución</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>seguro de enfermedad aceptado por la clínica</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>seguro de seguro de salud que acepta la instit...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1057 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Texto  Etiqueta\n",
       "0      ¿Puedo reservar un turno para la próxima semana?         0\n",
       "1     Quisiera agendar una cita médica para el marte...         0\n",
       "2     ¿Están disponibles los turnos para el especial...         0\n",
       "3     Necesito una cita con el odontólogo lo antes p...         0\n",
       "4     ¿Podría obtener un horario para una consulta d...         0\n",
       "...                                                 ...       ...\n",
       "1052                  seguro de salud de la institución         5\n",
       "1053  seguro de seguro de salud aceptado por la inst...         5\n",
       "1054  seguro de seguro médico que acepta la institución         5\n",
       "1055       seguro de enfermedad aceptado por la clínica         5\n",
       "1056  seguro de seguro de salud que acepta la instit...         5\n",
       "\n",
       "[1057 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = {}\n",
    "\n",
    "cont = 0\n",
    "\n",
    "for x in train_dataset['Etiqueta']:\n",
    "    if x not in indices:\n",
    "        indices[x] = cont\n",
    "        cont+=1\n",
    "        \n",
    "train_dataset['Etiqueta'] = train_dataset['Etiqueta'].map(indices)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 1.8798556625843048\n",
      "Epoch 2 Loss: 1.8639002740383148\n",
      "Epoch 3 Loss: 1.743060663342476\n",
      "Epoch 4 Loss: 1.767170011997223\n",
      "Epoch 5 Loss: 1.768181473016739\n",
      "Epoch 6 Loss: 1.7620436251163483\n",
      "Epoch 7 Loss: 1.7688672170042992\n",
      "Epoch 8 Loss: 1.7568030655384064\n",
      "Epoch 9 Loss: 1.7541908249258995\n",
      "Epoch 10 Loss: 1.7502980157732964\n",
      "Epoch 11 Loss: 1.7191012501716614\n",
      "Epoch 12 Loss: 1.7467118948698044\n",
      "Epoch 13 Loss: 1.7416902780532837\n",
      "Epoch 14 Loss: 1.7323157414793968\n",
      "Epoch 15 Loss: 1.7181469202041626\n",
      "Epoch 1 Loss: 2.0557513535022736\n",
      "Epoch 2 Loss: 1.7738358676433563\n",
      "Epoch 3 Loss: 1.7643640413880348\n",
      "Epoch 4 Loss: 1.7387757822871208\n",
      "Epoch 5 Loss: 1.772527925670147\n",
      "Epoch 6 Loss: 1.7556380331516266\n",
      "Epoch 7 Loss: 1.7414259910583496\n",
      "Epoch 8 Loss: 1.7524184808135033\n",
      "Epoch 9 Loss: 1.7385631054639816\n",
      "Epoch 10 Loss: 1.7352093905210495\n",
      "Epoch 11 Loss: 1.750987447798252\n",
      "Epoch 12 Loss: 1.7041757702827454\n",
      "Epoch 13 Loss: 1.7812691032886505\n",
      "Epoch 14 Loss: 1.729643851518631\n",
      "Epoch 15 Loss: 1.7194742932915688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('asistente\\\\tokenizer_config.json',\n",
       " 'asistente\\\\special_tokens_map.json',\n",
       " 'asistente\\\\vocab.txt',\n",
       " 'asistente\\\\added_tokens.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Configurar el modelo y el tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=8)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Configurar la validación cruzada K-Fold\n",
    "kfold = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "# Entrenamiento del modelo en cada fold\n",
    "for train_index, val_index in kfold.split(train_dataset):\n",
    "    train_data, val_data = train_dataset.iloc[train_index], train_dataset.iloc[val_index]\n",
    "    \n",
    "    \n",
    "    # Procesamiento de los datos de entrenamiento\n",
    "    train_encodings = tokenizer(train_dataset['Texto'].tolist(), truncation=True, padding=True, return_tensors='pt').to(device)\n",
    "    train_labels = torch.tensor(train_dataset['Etiqueta'].tolist()).to(device)\n",
    "\n",
    "\n",
    "    # Ajustar el modelo con los datos de entrenamiento\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)  # Ajusta el learning rate\n",
    "    criterion = torch.nn.CrossEntropyLoss()  # Define la función de pérdida\n",
    "\n",
    "    batch_size = 80  # Tamaño del batch\n",
    "    num_epochs = 10  # Número de epochs\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(list(zip(train_encodings['input_ids'], train_encodings['attention_mask'], train_labels)), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids, attention_mask, labels = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels) \n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "         \n",
    "        print(f\"Epoch {epoch+1} Loss: {epoch_loss / len(train_loader)}\")\n",
    "\n",
    "model.save_pretrained('asistente') # ruta para guardar el modelo\n",
    "tokenizer.save_pretrained('asistente') # ruta para guardar el tokenizer del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 10\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Suponiendo que tienes tus datos cargados en train_dataset\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Configurar el modelo y el tokenizer\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mBertForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbert-base-uncased\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m BertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\modeling_utils.py:3480\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3472\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[0;32m   3473\u001b[0m     (\n\u001b[0;32m   3474\u001b[0m         model,\n\u001b[0;32m   3475\u001b[0m         missing_keys,\n\u001b[0;32m   3476\u001b[0m         unexpected_keys,\n\u001b[0;32m   3477\u001b[0m         mismatched_keys,\n\u001b[0;32m   3478\u001b[0m         offload_index,\n\u001b[0;32m   3479\u001b[0m         error_msgs,\n\u001b[1;32m-> 3480\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[0;32m   3484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3487\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3488\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3491\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3492\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquantization_method\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mQuantizationMethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBITS_AND_BYTES\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3496\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3498\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_4bit \u001b[38;5;241m=\u001b[39m load_in_4bit\n\u001b[0;32m   3499\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_8bit \u001b[38;5;241m=\u001b[39m load_in_8bit\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\modeling_utils.py:3824\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[1;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[0;32m   3814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m# Whole checkpoint\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     mismatched_keys \u001b[38;5;241m=\u001b[39m _find_mismatched_keys(\n\u001b[0;32m   3817\u001b[0m         state_dict,\n\u001b[0;32m   3818\u001b[0m         model_state_dict,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3822\u001b[0m         ignore_mismatched_sizes,\n\u001b[0;32m   3823\u001b[0m     )\n\u001b[1;32m-> 3824\u001b[0m     error_msgs \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3825\u001b[0m     offload_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3826\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3827\u001b[0m     \u001b[38;5;66;03m# Sharded checkpoint or whole but low_cpu_mem_usage==True\u001b[39;00m\n\u001b[0;32m   3828\u001b[0m \n\u001b[0;32m   3829\u001b[0m     \u001b[38;5;66;03m# This should always be a list but, just to be sure.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\modeling_utils.py:571\u001b[0m, in \u001b[0;36m_load_state_dict_into_model\u001b[1;34m(model_to_load, state_dict, start_prefix)\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    569\u001b[0m             load(child, state_dict, prefix \u001b[38;5;241m+\u001b[39m name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 571\u001b[0m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_prefix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;66;03m# Delete `state_dict` so it could be collected by GC earlier. Note that `state_dict` is a copy of the argument, so\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;66;03m# it's safe to delete it.\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m state_dict\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\modeling_utils.py:569\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[1;34m(module, state_dict, prefix)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 569\u001b[0m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\modeling_utils.py:569\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[1;34m(module, state_dict, prefix)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 569\u001b[0m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping similar frames: _load_state_dict_into_model.<locals>.load at line 569 (3 times)]\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\modeling_utils.py:569\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[1;34m(module, state_dict, prefix)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 569\u001b[0m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\modeling_utils.py:565\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[1;34m(module, state_dict, prefix)\u001b[0m\n\u001b[0;32m    563\u001b[0m                     module\u001b[38;5;241m.\u001b[39m_load_from_state_dict(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 565\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_from_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:2040\u001b[0m, in \u001b[0;36mModule._load_from_state_dict\u001b[1;34m(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\u001b[0m\n\u001b[0;32m   2038\u001b[0m                 \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, input_param)\n\u001b[0;32m   2039\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2040\u001b[0m             \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_param\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2041\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m   2042\u001b[0m     error_msgs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhile copying the parameter named \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2043\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhose dimensions in the model are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2044\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhose dimensions in the checkpoint are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_param\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2045\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124man exception occurred : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;241m.\u001b[39margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2046\u001b[0m                       )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Suponiendo que tienes tus datos cargados en train_dataset\n",
    "\n",
    "# Configurar el modelo y el tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=8)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Configurar la validación cruzada K-Fold\n",
    "kfold = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "\n",
    "best_validation_loss = float('inf')  # Inicializa la mejor pérdida de validación\n",
    "best_model_path = 'best_model.pth'  # Ruta para guardar el mejor modelo\n",
    "\n",
    "# Entrenamiento del modelo en cada fold\n",
    "for train_index, val_index in kfold.split(train_dataset):\n",
    "    train_data, val_data = train_dataset.iloc[train_index], train_dataset.iloc[val_index]\n",
    "\n",
    "    # Procesamiento de los datos de entrenamiento\n",
    "    train_encodings = tokenizer(train_data['Texto'].tolist(), truncation=True, padding=True, return_tensors='pt').to(device)\n",
    "    train_labels = torch.tensor(train_data['Etiqueta'].tolist()).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        params=model.parameters(),\n",
    "        lr=0.001,\n",
    "        eps=1e-8,\n",
    "        amsgrad=True,\n",
    "        fused=True\n",
    "    )\n",
    "    criterion = torch.nn.CrossEntropyLoss()  # Define la función de pérdida\n",
    "\n",
    "    batch_size = 70  # Tamaño del batch\n",
    "    num_epochs = 15  # Número de epochs\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(list(zip(train_encodings['input_ids'], train_encodings['attention_mask'], train_labels)), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids, attention_mask, labels = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # Proceso de validación\n",
    "        model.eval()\n",
    "        val_encodings = tokenizer(val_data['Texto'].tolist(), truncation=True, padding=True, return_tensors='pt').to(device)\n",
    "        val_labels = torch.tensor(val_data['Etiqueta'].tolist()).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_loader = torch.utils.data.DataLoader(list(zip(val_encodings['input_ids'], val_encodings['attention_mask'], val_labels)), batch_size=batch_size)\n",
    "            val_loss = 0.0\n",
    "            predictions = []\n",
    "\n",
    "            for batch in val_loader:\n",
    "                input_ids, attention_mask, labels = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs.loss\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                logits = outputs.logits\n",
    "                predictions.extend(logits.argmax(dim=-1).cpu().numpy())\n",
    "\n",
    "        val_accuracy = accuracy_score(val_data['Etiqueta'], predictions)\n",
    "\n",
    "        if val_loss < best_validation_loss:\n",
    "            best_validation_loss = val_loss\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} Training Loss: {epoch_loss / len(train_loader)} Validation Loss: {val_loss / len(val_loader)} Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Carga el mejor modelo guardado\n",
    "best_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=8)\n",
    "best_model.load_state_dict(torch.load(best_model_path))\n",
    "best_model.to(device)\n",
    "\n",
    "# Guardar el modelo y el tokenizer\n",
    "best_model.save_pretrained('asistente')\n",
    "tokenizer.save_pretrained('asistente')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "# Ruta donde has guardado el modelo\n",
    "ruta_del_modelo = \"asistente\"\n",
    "\n",
    "# Cargar el modelo y el tokenizador\n",
    "model = BertForSequenceClassification.from_pretrained(ruta_del_modelo)\n",
    "tokenizer = BertTokenizer.from_pretrained(ruta_del_modelo)\n",
    "\n",
    "# Ejemplo de nueva entrada para hacer predicciones\n",
    "nuevo_texto = \"Quiero un turno\"\n",
    "\n",
    "# Tokenizar el texto de entrada\n",
    "inputs = tokenizer(nuevo_texto, truncation=True, padding=True, return_tensors='pt')\n",
    "\n",
    "# Obtener las predicciones del modelo\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    predictions = outputs.logits\n",
    "\n",
    "# Aplicar la función softmax a los logits para obtener probabilidades\n",
    "probabilities = F.softmax(predictions, dim=1)\n",
    "\n",
    "etiqueta_idx = torch.argmax(probabilities)\n",
    "\n",
    "print(etiqueta_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intencion(texto):\n",
    "    alm = {v: k for k, v in indices.items()}\n",
    "    inputs = tokenizer(texto, truncation=True, padding=True, return_tensors='pt')\n",
    "\n",
    "    # Obtener las predicciones del modelo\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = outputs.logits\n",
    "\n",
    "    # Aplicar la función softmax a los logits para obtener probabilidades\n",
    "    probabilities = F.softmax(predictions, dim=1)\n",
    "\n",
    "    etiqueta_idx = torch.argmax(probabilities)\n",
    "    \n",
    "    return alm[etiqueta_idx.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "consultas = {\n",
    "    'consulta_turno': [\n",
    "        '¿Puedo obtener un turno para una consulta con el Dr. Smith?',\n",
    "        'Quisiera programar una cita médica para el próximo lunes, ¿es posible?',\n",
    "        '¿Están disponibles los turnos para pediatría mañana por la tarde?'\n",
    "    ],\n",
    "    'pregunta_horario': [\n",
    "        '¿Cuál es el horario de atención del departamento de emergencias?',\n",
    "        '¿A qué hora abre la clínica los sábados?',\n",
    "        '¿Hasta qué hora están recibiendo pacientes hoy?'\n",
    "    ],\n",
    "    'pregunta_especialidad': [\n",
    "        '¿Podrían decirme si tienen un especialista en cardiología disponible?',\n",
    "        '¿Quién es el neurólogo de guardia hoy?',\n",
    "        '¿Tienen médicos especializados en traumatología?'\n",
    "    ],\n",
    "    'consulta_resultados': [\n",
    "        'Me gustaría saber si mis resultados de análisis de sangre ya están disponibles.',\n",
    "        '¿Dónde puedo ver los resultados de mi radiografía?',\n",
    "        '¿Los resultados de mi ecografía ya están listos?'\n",
    "    ],\n",
    "    'pregunta_receta': [\n",
    "        '¿Puedo solicitar una receta para mi medicamento?',\n",
    "        'Necesito una receta para renovar mi medicación, ¿cómo puedo obtenerla?',\n",
    "        '¿El médico puede enviarme la receta por correo electrónico?'\n",
    "    ],\n",
    "    'consulta_seguro': [\n",
    "        '¿Aceptan mi seguro médico para consultas en esta clínica?',\n",
    "        '¿Qué tipos de seguros médicos son aceptados aquí?',\n",
    "        '¿Pueden informarme sobre los procedimientos cubiertos por mi seguro de salud?'\n",
    "    ],\n",
    "    'pregunta_certificado': [\n",
    "        '¿Es posible obtener un certificado médico para faltar al trabajo?',\n",
    "        '¿Cómo puedo obtener un certificado de aptitud física?',\n",
    "        '¿Pueden proporcionarme un certificado para justificar una ausencia escolar?'\n",
    "    ],\n",
    "    'pregunta_emergencia': [\n",
    "        'Tengo una emergencia médica, ¿qué debo hacer?',\n",
    "        '¿Dónde está ubicado el área de emergencias?',\n",
    "        '¿Cuál es el número de contacto para emergencias fuera del horario de atención?'\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consulta_turno  :  Prediccion :  consulta_turno  |  ¿Puedo obtener un turno para una consulta con el Dr. Smith?\n",
      "consulta_turno  :  Prediccion :  consulta_turno  |  Quisiera programar una cita médica para el próximo lunes, ¿es posible?\n",
      "consulta_turno  :  Prediccion :  consulta_turno  |  ¿Están disponibles los turnos para pediatría mañana por la tarde?\n",
      "pregunta_horario  :  Prediccion :  consulta_turno  |  ¿Cuál es el horario de atención del departamento de emergencias?\n",
      "pregunta_horario  :  Prediccion :  consulta_turno  |  ¿A qué hora abre la clínica los sábados?\n",
      "pregunta_horario  :  Prediccion :  consulta_turno  |  ¿Hasta qué hora están recibiendo pacientes hoy?\n",
      "pregunta_especialidad  :  Prediccion :  consulta_turno  |  ¿Podrían decirme si tienen un especialista en cardiología disponible?\n",
      "pregunta_especialidad  :  Prediccion :  consulta_turno  |  ¿Quién es el neurólogo de guardia hoy?\n",
      "pregunta_especialidad  :  Prediccion :  consulta_turno  |  ¿Tienen médicos especializados en traumatología?\n",
      "consulta_resultados  :  Prediccion :  consulta_turno  |  Me gustaría saber si mis resultados de análisis de sangre ya están disponibles.\n",
      "consulta_resultados  :  Prediccion :  consulta_turno  |  ¿Dónde puedo ver los resultados de mi radiografía?\n",
      "consulta_resultados  :  Prediccion :  consulta_turno  |  ¿Los resultados de mi ecografía ya están listos?\n",
      "pregunta_receta  :  Prediccion :  consulta_turno  |  ¿Puedo solicitar una receta para mi medicamento?\n",
      "pregunta_receta  :  Prediccion :  consulta_turno  |  Necesito una receta para renovar mi medicación, ¿cómo puedo obtenerla?\n",
      "pregunta_receta  :  Prediccion :  consulta_turno  |  ¿El médico puede enviarme la receta por correo electrónico?\n",
      "consulta_seguro  :  Prediccion :  consulta_turno  |  ¿Aceptan mi seguro médico para consultas en esta clínica?\n",
      "consulta_seguro  :  Prediccion :  consulta_turno  |  ¿Qué tipos de seguros médicos son aceptados aquí?\n",
      "consulta_seguro  :  Prediccion :  consulta_turno  |  ¿Pueden informarme sobre los procedimientos cubiertos por mi seguro de salud?\n",
      "pregunta_certificado  :  Prediccion :  consulta_turno  |  ¿Es posible obtener un certificado médico para faltar al trabajo?\n",
      "pregunta_certificado  :  Prediccion :  consulta_turno  |  ¿Cómo puedo obtener un certificado de aptitud física?\n",
      "pregunta_certificado  :  Prediccion :  consulta_turno  |  ¿Pueden proporcionarme un certificado para justificar una ausencia escolar?\n",
      "pregunta_emergencia  :  Prediccion :  consulta_turno  |  Tengo una emergencia médica, ¿qué debo hacer?\n",
      "pregunta_emergencia  :  Prediccion :  consulta_turno  |  ¿Dónde está ubicado el área de emergencias?\n",
      "pregunta_emergencia  :  Prediccion :  consulta_turno  |  ¿Cuál es el número de contacto para emergencias fuera del horario de atención?\n"
     ]
    }
   ],
   "source": [
    "for x,y in consultas.items():\n",
    "    for e in y:\n",
    "        print(x,' : ','Prediccion : ',intencion(e), ' | ',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'consulta_turno'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intencion('Tienen medicos clinicos en el hospital?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
